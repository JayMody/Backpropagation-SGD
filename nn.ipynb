{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in ./.venv/lib/python3.11/site-packages (1.26.2)\n",
      "Requirement already satisfied: datasets in ./.venv/lib/python3.11/site-packages (2.16.0)\n",
      "Requirement already satisfied: Pillow in ./.venv/lib/python3.11/site-packages (10.1.0)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.11/site-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in ./.venv/lib/python3.11/site-packages (from datasets) (14.0.2)\n",
      "Requirement already satisfied: pyarrow-hotfix in ./.venv/lib/python3.11/site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in ./.venv/lib/python3.11/site-packages (from datasets) (0.3.7)\n",
      "Requirement already satisfied: pandas in ./.venv/lib/python3.11/site-packages (from datasets) (2.1.4)\n",
      "Requirement already satisfied: requests>=2.19.0 in ./.venv/lib/python3.11/site-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in ./.venv/lib/python3.11/site-packages (from datasets) (4.66.1)\n",
      "Requirement already satisfied: xxhash in ./.venv/lib/python3.11/site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in ./.venv/lib/python3.11/site-packages (from datasets) (0.70.15)\n",
      "Requirement already satisfied: fsspec<=2023.10.0,>=2023.1.0 in ./.venv/lib/python3.11/site-packages (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets) (2023.10.0)\n",
      "Requirement already satisfied: aiohttp in ./.venv/lib/python3.11/site-packages (from datasets) (3.9.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.4 in ./.venv/lib/python3.11/site-packages (from datasets) (0.20.1)\n",
      "Requirement already satisfied: packaging in ./.venv/lib/python3.11/site-packages (from datasets) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.venv/lib/python3.11/site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.venv/lib/python3.11/site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.venv/lib/python3.11/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./.venv/lib/python3.11/site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.venv/lib/python3.11/site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./.venv/lib/python3.11/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.venv/lib/python3.11/site-packages (from huggingface-hub>=0.19.4->datasets) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.11/site-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.11/site-packages (from requests>=2.19.0->datasets) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.11/site-packages (from requests>=2.19.0->datasets) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.11/site-packages (from requests>=2.19.0->datasets) (2023.11.17)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.11/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.11/site-packages (from pandas->datasets) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in ./.venv/lib/python3.11/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install numpy datasets Pillow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    x = np.exp(x - np.max(x, axis=-1, keepdims=True))\n",
    "    return x / np.sum(x, axis=-1, keepdims=True)\n",
    "\n",
    "def log_softmax(x):\n",
    "    x = x - np.max(x, axis=-1, keepdims=True)\n",
    "    return x - np.log(np.sum(np.exp(x), axis=-1, keepdims=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(logits, y):\n",
    "    return -log_softmax(logits)[y]\n",
    "\n",
    "def d_loss_fn(logits, y):\n",
    "    p = softmax(logits)\n",
    "    p[y] -= 1\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def d_relu(x):\n",
    "    return np.where(x > 0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_params(in_size: int, out_size: int, hidden_sizes: list[int]):\n",
    "    dims = [in_size] + hidden_sizes + [out_size]\n",
    "    params = []\n",
    "    for nin, nout in zip(dims[:-1], dims[1:]):\n",
    "        # xavier uniform initialization for weight matrixes\n",
    "        a = (6 / (nin + nout)) ** 0.5\n",
    "        w = np.random.uniform(-a, a, size=[nin, nout])\n",
    "        b = np.zeros(nout)\n",
    "        params.append([w, b])\n",
    "    return params\n",
    "\n",
    "def forward(x, params):\n",
    "    tape = [(None, x)]\n",
    "    for w, b in params:\n",
    "        z = x @ w + b\n",
    "        x = relu(z)\n",
    "        tape.append((z, x))\n",
    "    return z, tape[:-1]\n",
    "\n",
    "def backprop(x, y, params):\n",
    "    logits, tape = forward(x, params)\n",
    "\n",
    "    grad = []\n",
    "    error = d_loss_fn(logits, y)\n",
    "    for (z, a), (w, _) in zip(reversed(tape), reversed(params)):\n",
    "        grad.append((error * a.reshape(-1, 1), error))\n",
    "        if z is not None:\n",
    "            error = error @ w.T\n",
    "            error = error * d_relu(z)\n",
    "    grad = list(reversed(grad))\n",
    "    \n",
    "    return grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training on MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jay/code/backpropagation/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0 | acc: 0.0416\n",
      "step: 100 | acc: 0.0720\n",
      "step: 200 | acc: 0.0867\n",
      "step: 300 | acc: 0.1102\n",
      "step: 400 | acc: 0.1325\n",
      "step: 500 | acc: 0.1475\n",
      "step: 600 | acc: 0.1478\n",
      "step: 700 | acc: 0.1516\n",
      "step: 800 | acc: 0.1569\n",
      "step: 900 | acc: 0.1607\n",
      "step: 1000 | acc: 0.1648\n",
      "step: 1100 | acc: 0.1729\n",
      "step: 1200 | acc: 0.1760\n",
      "step: 1300 | acc: 0.1842\n",
      "step: 1400 | acc: 0.1783\n",
      "step: 1500 | acc: 0.2049\n",
      "step: 1600 | acc: 0.2198\n",
      "step: 1700 | acc: 0.2284\n",
      "step: 1800 | acc: 0.2839\n",
      "step: 1900 | acc: 0.3148\n",
      "step: 2000 | acc: 0.3635\n",
      "step: 2100 | acc: 0.3722\n",
      "step: 2200 | acc: 0.4194\n",
      "step: 2300 | acc: 0.4488\n",
      "step: 2400 | acc: 0.4823\n",
      "step: 2500 | acc: 0.4696\n",
      "step: 2600 | acc: 0.5475\n",
      "step: 2700 | acc: 0.5767\n",
      "step: 2800 | acc: 0.5687\n",
      "step: 2900 | acc: 0.5949\n",
      "step: 3000 | acc: 0.5344\n",
      "step: 3100 | acc: 0.6423\n",
      "step: 3200 | acc: 0.6110\n",
      "step: 3300 | acc: 0.6774\n",
      "step: 3400 | acc: 0.6481\n",
      "step: 3500 | acc: 0.6719\n",
      "step: 3600 | acc: 0.6516\n",
      "step: 3700 | acc: 0.6714\n",
      "step: 3800 | acc: 0.6874\n",
      "step: 3900 | acc: 0.6449\n",
      "step: 4000 | acc: 0.6733\n",
      "step: 4100 | acc: 0.6600\n",
      "step: 4200 | acc: 0.6955\n",
      "step: 4300 | acc: 0.6988\n",
      "step: 4400 | acc: 0.6967\n",
      "step: 4500 | acc: 0.7162\n",
      "step: 4600 | acc: 0.7198\n",
      "step: 4700 | acc: 0.7280\n",
      "step: 4800 | acc: 0.7181\n",
      "step: 4900 | acc: 0.7181\n",
      "step: 5000 | acc: 0.7488\n",
      "step: 5100 | acc: 0.7458\n",
      "step: 5200 | acc: 0.7512\n",
      "step: 5300 | acc: 0.7585\n",
      "step: 5400 | acc: 0.7590\n",
      "step: 5500 | acc: 0.7638\n",
      "step: 5600 | acc: 0.7658\n",
      "step: 5700 | acc: 0.7565\n",
      "step: 5800 | acc: 0.7671\n",
      "step: 5900 | acc: 0.7662\n",
      "step: 6000 | acc: 0.7624\n",
      "step: 6100 | acc: 0.7600\n",
      "step: 6200 | acc: 0.7862\n",
      "step: 6300 | acc: 0.7591\n",
      "step: 6400 | acc: 0.7658\n",
      "step: 6500 | acc: 0.7987\n",
      "step: 6600 | acc: 0.8029\n",
      "step: 6700 | acc: 0.7935\n",
      "step: 6800 | acc: 0.7995\n",
      "step: 6900 | acc: 0.7872\n",
      "step: 7000 | acc: 0.8092\n",
      "step: 7100 | acc: 0.7978\n",
      "step: 7200 | acc: 0.8136\n",
      "step: 7300 | acc: 0.7995\n",
      "step: 7400 | acc: 0.7968\n",
      "step: 7500 | acc: 0.8042\n",
      "step: 7600 | acc: 0.8019\n",
      "step: 7700 | acc: 0.8219\n",
      "step: 7800 | acc: 0.8153\n",
      "step: 7900 | acc: 0.8064\n",
      "step: 8000 | acc: 0.8301\n",
      "step: 8100 | acc: 0.8296\n",
      "step: 8200 | acc: 0.8257\n",
      "step: 8300 | acc: 0.8179\n",
      "step: 8400 | acc: 0.8262\n",
      "step: 8500 | acc: 0.8299\n",
      "step: 8600 | acc: 0.8232\n",
      "step: 8700 | acc: 0.8330\n",
      "step: 8800 | acc: 0.8357\n",
      "step: 8900 | acc: 0.8246\n",
      "step: 9000 | acc: 0.8346\n",
      "step: 9100 | acc: 0.8408\n",
      "step: 9200 | acc: 0.8373\n",
      "step: 9300 | acc: 0.8414\n",
      "step: 9400 | acc: 0.8439\n",
      "step: 9500 | acc: 0.8397\n",
      "step: 9600 | acc: 0.8388\n",
      "step: 9700 | acc: 0.8456\n",
      "step: 9800 | acc: 0.8483\n",
      "step: 9900 | acc: 0.8433\n"
     ]
    }
   ],
   "source": [
    "def train_mnist():\n",
    "    import datasets\n",
    "\n",
    "    mnist = datasets.load_dataset(\"mnist\")\n",
    "    xtrain, ytrain = np.array(mnist[\"train\"][\"image\"]).reshape(-1, 784) / 255.0, mnist[\"train\"][\"label\"]\n",
    "    xtest, ytest = np.array(mnist[\"test\"][\"image\"]).reshape(-1, 784) / 255.0, mnist[\"test\"][\"label\"]\n",
    "\n",
    "    def compute_val_acc(params):\n",
    "        val_correct = 0\n",
    "        for x, y in zip(xtest, ytest):\n",
    "            z, _ = forward(x, params)\n",
    "            val_correct += np.argmax(z) == y\n",
    "        return val_correct / len(xtest)\n",
    "\n",
    "    params = init_params(784, 20, [32, 16])\n",
    "    lr = 1e-3\n",
    "    n_examples = 10000\n",
    "    log_every_n_steps = 100\n",
    "\n",
    "    for step in range(n_examples):\n",
    "        # get random training example\n",
    "        i = np.random.randint(len(xtrain))\n",
    "        x, y = xtrain[i], ytrain[i]\n",
    "\n",
    "        # compute gradient\n",
    "        grad = backprop(x, y, params)\n",
    "\n",
    "        # update the parameters\n",
    "        for k in range(len(params)):\n",
    "            params[k][0] -= lr * grad[k][0] \n",
    "            params[k][1] -= lr * grad[k][1]\n",
    "\n",
    "        # log\n",
    "        if step % log_every_n_steps == 0:\n",
    "            print(f\"step: {step} | acc: {compute_val_acc(params):.4f}\")\n",
    "\n",
    "train_mnist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verifying Backprop\n",
    "\n",
    "We can verify that our backprop gives a correct by comparing it with a numerically computed approximation of the gradient, which we can obtain via (using a small value for $h$):\n",
    "\n",
    "$$\n",
    "f'(x) = \\lim_{h\\rightarrow 0} \\frac{f(x + h) - f(x)}{h}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Relative Difference: 0.04297993519788267\n",
      "Mean Relative Difference: 1.0049954290594662e-05\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "def numerical(x, y, params, h=1e-8):\n",
    "    compute_loss = lambda params: loss_fn(forward(x, params)[0], y)  # noqa: E731\n",
    "\n",
    "    base_loss = compute_loss(params)\n",
    "\n",
    "    grad = copy.deepcopy(params)\n",
    "    for i in range(len(params)):\n",
    "        for j in range(len(params[i])):\n",
    "            for k in np.ndindex(params[i][j].shape):\n",
    "                prev_value = params[i][j][k]\n",
    "                params[i][j][k] += h\n",
    "                grad[i][j][k] = (compute_loss(params) - base_loss) / h\n",
    "                params[i][j][k] = prev_value\n",
    "\n",
    "    return grad\n",
    "\n",
    "def verify():\n",
    "    x, y = np.random.randn(256), np.random.randint(4)\n",
    "\n",
    "    params = init_params(256, 4, [128, 64, 32, 16, 8])\n",
    "    agrad = backprop(x, y, params)\n",
    "    ngrad = numerical(x, y, params)\n",
    "\n",
    "    rel_diffs = []\n",
    "    for (aw, ab), (bw, bb) in zip(agrad, ngrad):\n",
    "        rel_diffs += (abs(aw - bw) / (abs(aw) + np.finfo(aw.dtype).smallest_subnormal)).flatten().tolist()\n",
    "        rel_diffs += (abs(ab - bb) / (abs(bb) + np.finfo(aw.dtype).smallest_subnormal)).flatten().tolist()\n",
    "    \n",
    "    rel_diffs = np.array(rel_diffs)\n",
    "    \n",
    "    print(\"Max Relative Difference:\", rel_diffs.max())\n",
    "    print(\"Mean Relative Difference:\", rel_diffs.mean())\n",
    "\n",
    "verify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
